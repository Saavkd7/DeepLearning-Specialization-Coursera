{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ed0c90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gradient_check(parameters, gradients, X, Y, epsilon=1e-7):\n",
    "    \"\"\"\n",
    "    Checks if backward_propagation computes the gradient correctly.\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", etc.\n",
    "    gradients -- python dictionary containing your gradients \"dW1\", \"db1\", \"dW2\", \"db2\", etc.\n",
    "    X -- input data of shape (input_size, m)\n",
    "    Y -- true labels\n",
    "    epsilon -- tiny shift to the input to compute approximated gradient\n",
    "    \n",
    "    Returns:\n",
    "    difference -- difference between the approximated gradient and the backward propagation gradient\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Convert dictionary parameters to a single vector (theta)\n",
    "    # (Helper function 'dictionary_to_vector' flattens W1, b1... into a long 1D array)\n",
    "    parameters_values, _ = dictionary_to_vector(parameters)\n",
    "    \n",
    "    # 2. Convert dictionary gradients to a single vector (grad)\n",
    "    grad = gradients_to_vector(gradients)\n",
    "    \n",
    "    # Initialize the vector for numerical approximation\n",
    "    num_parameters = parameters_values.shape[0]\n",
    "    J_plus = np.zeros((num_parameters, 1))\n",
    "    J_minus = np.zeros((num_parameters, 1))\n",
    "    gradapprox = np.zeros((num_parameters, 1))\n",
    "    \n",
    "    # 3. Loop over every parameter to compute its numerical gradient\n",
    "    for i in range(num_parameters):\n",
    "        \n",
    "        # Save the original value so we can restore it later\n",
    "        thetaplus = np.copy(parameters_values)\n",
    "        thetaminus = np.copy(parameters_values)\n",
    "        \n",
    "        # Compute J_plus [J(theta + epsilon)]\n",
    "        thetaplus[i][0] = thetaplus[i][0] + epsilon\n",
    "        # (Helper function 'vector_to_dictionary' converts vector back to W1, b1...)\n",
    "        J_plus[i], _ = forward_propagation_n(X, Y, vector_to_dictionary(thetaplus))\n",
    "        \n",
    "        # Compute J_minus [J(theta - epsilon)]\n",
    "        thetaminus[i][0] = thetaminus[i][0] - epsilon\n",
    "        J_minus[i], _ = forward_propagation_n(X, Y, vector_to_dictionary(thetaminus))\n",
    "        \n",
    "        # Compute Grad Approx (Two-sided difference)\n",
    "        gradapprox[i] = (J_plus[i] - J_minus[i]) / (2 * epsilon)\n",
    "    \n",
    "    # 4. Compare gradapprox (Numerical) vs grad (Analytical/Backprop)\n",
    "    # We use the Euclidean distance formula normalized by the lengths\n",
    "    numerator = np.linalg.norm(grad - gradapprox)\n",
    "    denominator = np.linalg.norm(grad) + np.linalg.norm(gradapprox)\n",
    "    difference = numerator / denominator\n",
    "\n",
    "    if difference > 2e-7:\n",
    "        print(f\"\\033[91mMistake likely in backward propagation! difference = {difference}\\033[0m\")\n",
    "    else:\n",
    "        print(f\"\\033[92mYour backward propagation works perfectly. difference = {difference}\\033[0m\")\n",
    "        \n",
    "    return difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8ae387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
