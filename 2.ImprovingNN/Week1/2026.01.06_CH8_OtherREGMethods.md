# My Diary

Today  **{{DATE_PRETTY}}**.

## General Counter
It has been    **{{DAY_SINCE_2025_08_18}}** days since I started this diary.

# Repository Counter

Day **{{DAYS_SINCE_REPO_START}}** From I started this repository



# Deep Learning Techniques: Augmentation & Early Stopping

## 1. Data Augmentation
If you have High Variance (Overfitting), the best fix is **More Data**. But data is expensive. Data Augmentation is a "cheat" to get more data for free.

### How it Works
You take your existing training examples and apply random, realistic transformations to create "new" examples.
* **Computer Vision:**
    * **Mirroring:** Flip the image horizontally. (A cat facing left is still a cat).
    * **Random Cropping:** Zoom into random parts of the image.
    * **Rotation/Shearing:** Tilt the image slightly.
* **OCR (Digits):** Apply random warps and distortions to the handwriting.

### The Intuition
By training on these distorted images, you teach the model **invariance**. You tell the algorithm: *"This is a cat, and it remains a cat even if it is rotated or zoomed in."* This makes the model robust without collecting new samples.

---

## 2. Early Stopping
This is a technique where you stop training *before* the model has fully converged.

### The Mechanism
1.  **Plot Training Error:** It decreases monotonically (blue line).
2.  **Plot Dev Set Error:** It decreases for a while, but eventually **starts to go back up** (purple line). This "U-turn" is the moment overfitting begins.
3.  **Action:** Stop training at the lowest point of the Dev Set Error curve.

### Why it Works (The "Mid-Size" W)
* **Start:** Weights $W$ are initialized near 0.
* **End:** Weights $W$ grow large to fit complex patterns (overfitting).
* **Early Stop:** You catch $W$ in the middle. The weights are "mid-sized"â€”large enough to learn, but small enough to avoid overfitting. This mimics the effect of L2 Regularization.

### The Downside: Orthogonalization
Andrew Ng prefers L2 Regularization over Early Stopping because Early Stopping violates the principle of **Orthogonalization** (doing one thing at a time).
* **The Goal:** You want to (1) Optimize Cost $J$ and (2) Prevent Overfitting.
* **The Problem:** Early Stopping mixes these two. By stopping early, you are forcibly preventing the optimizer from minimizing $J$ fully. It tries to solve two problems with one button, which makes tuning harder.
* **The Alternative:** Use **L2 Regularization**. It lets you optimize $J$ all the way to the end, while the penalty term handles the overfitting independently.
