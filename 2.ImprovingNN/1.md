# My Diary

Today  **{{DATE_PRETTY}}**.

## General Counter
It has been    **{{DAY_SINCE_2025_08_18}}** days since I started this diary.

# Repository Counter

Day **{{DAYS_SINCE_REPO_START}}** From I started this repository



# Debugging Deep Nets: Numerical Gradient Approximation

## 1. Executive Summary
When you implement Backpropagation, it is easy to make subtle bugs that are hard to detect (the model trains, but poorly).
To verify your code, you use **Gradient Checking**. This involves calculating the slope (derivative) of your Cost Function manually using a simple geometry formula ("Rise over Run"). If this manual value matches your Backpropagation output, your code is correct.
* **The Trick:** Use a **Two-Sided Difference** (checking both left and right of the point) rather than a One-Sided Difference. It is twice as slow but much more accurate.

## 2. The Technique: Two-Sided Difference

To approximate the slope (gradient $g$) of a function $f$ at parameter $\theta$:

### The Formula
Instead of just nudging $\theta$ to the right ($\theta + \epsilon$), we nudge it both ways to create a centered triangle.
$$g(\theta) \approx \frac{f(\theta + \epsilon) - f(\theta - \epsilon)}{2\epsilon}$$
* **$\epsilon$ (Epsilon):** A tiny number, typically $10^{-7}$ or $0.01$.

### Concrete Example
Let $f(\theta) = \theta^3$. Let's find the slope at $\theta = 1$ (True derivative is $3\theta^2 = 3$).
* **Using $\epsilon = 0.01$:**
    * $\theta_{right} = 1.01 \rightarrow (1.01)^3 = 1.030301$
    * $\theta_{left} = 0.99 \rightarrow (0.99)^3 = 0.970299$
    * **Difference:** $1.030301 - 0.970299 = 0.060002$
    * **Divide by $2\epsilon$:** $0.060002 / 0.02 = \mathbf{3.0001}$
* **Result:** The error is $0.0001$. This is incredibly close to the true value of $3$.

## 3. "In Plain English"

### The "Triangle" Analogy
Imagine you are standing on a hill ($\theta$) and want to know the steepness (gradient).
* **One-Sided (Bad Way):** You look at a point one step ahead of you and draw a line. This line ignores the shape of the hill behind you.
* **Two-Sided (Good Way):** You look at a point one step ahead **and** one step behind you. You connect them with a straight line (the green triangle in the diagram). This line balances out the curvature of the hill, giving you a near-perfect estimate of the steepness right where you are standing.

## 4. Expert Nuance

### Why Two-Sided? ($O(\epsilon^2)$ vs $O(\epsilon)$)
For those familiar with Calculus (Taylor Series), the error rates differ significantly:
* **One-Sided Difference:** The error is proportional to $\epsilon$ ($O(\epsilon)$).
    * If $\epsilon = 0.01$, error $\approx 0.03$.
* **Two-Sided Difference:** The error is proportional to $\epsilon^2$ ($O(\epsilon^2)$).
    * If $\epsilon = 0.01$, error $\approx 0.0001$.
* **Takeaway:** Since $\epsilon$ is already tiny ($<1$), squaring it makes the error infinitesimally small. Always use the two-sided formula for Gradient Checking, even though it requires computing the cost function twice.
