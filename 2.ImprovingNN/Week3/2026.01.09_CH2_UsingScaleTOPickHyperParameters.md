# My Diary

Today  **{{DATE_PRETTY}}**.

## General Counter
It has been    **{{DAY_SINCE_2025_08_18}}** days since I started this diary.

# Repository Counter

Day **{{DAYS_SINCE_REPO_START}}** From I started this repository


# Hyperparameter Tuning: Choosing the Right Scale

## 1. When to use a Linear Scale
For some hyperparameters, sampling uniformly at random (Linear Scale) works perfectly fine.
* **Examples:**
    * **Number of Hidden Units ($n^{[l]}$):** If you are searching between 50 and 100, simply picking random integers in that range is reasonable.
    * **Number of Layers ($L$):** If searching between 2 and 4, picking 2, 3, or 4 with equal probability is correct.


## 2. The Problem with Linear Scale (Learning Rate $\alpha$)
Suppose you want to tune the learning rate $\alpha$ between **0.0001** and **1**.
If you sample uniformly on a number line:
* **90%** of your resources will be spent searching between **0.1 and 1**.
* **10%** of your resources will be spent searching between **0.0001 and 0.1**.

This is inefficient because the difference between 0.1 and 1 is just one order of magnitude, while the difference between 0.0001 and 0.1 covers three orders of magnitude. You need to explore the small values just as densely as the large ones.

## 3. The Solution: Log Scale Sampling
To fix this, you should sample on a **Logarithmic Scale**. This ensures you dedicate equal resources to each order of magnitude (e.g., $0.0001 \to 0.001$ gets as many samples as $0.1 \to 1$).

### Implementation (Python)
To sample $\alpha$ between $10^a$ and $10^b$:
1.  **Calculate Limits:** $a = \log_{10}(0.0001) = -4$, $b = \log_{10}(1) = 0$.
2.  **Sample $r$:** Pick a random number $r$ uniformly between $a$ and $b$ (e.g., $-4$ and $0$).
3.  **Compute $\alpha$:** Set $\alpha = 10^r$.

```python
r = -4 * np.random.rand() # r is between -4 and 0
alpha = 10 ** r           # alpha is between 10^-4 and 10^0


```

```python
resultados = [] # Tu libreta de notas

for i in range(10):
    r = -4 * np.random.rand()
    a = 10**r
    score = entrenar_modelo(a) # La nota que saca la IA
    resultados.append((score, a))

# Ver el mejor
resultados.sort(reverse=True)
print(f"Mejor alpha: {resultados[0][1]}")
```
### 4. The Special Case: Momentum ($\beta$)
Tuning $\beta$ (Momentum) requires a trick because the parameter is highly sensitive when it gets close to 1.

* **Range:** $0.9$ to $0.999$.
* **The Issue:** Sensitivity near 1.
    * Going from $0.9 \to 0.9005$ makes almost no difference (averaging $\approx 10$ days).
    * Going from $0.999 \to 0.9995$ is huge! It doubles the averaging window from 1,000 days to 2,000 days.
* **The Fix:** Sample **$1 - \beta$** on a log scale instead.
    * Range for $1-\beta$: $0.1$ to $0.001$.
    * Sample $r$ between $-1$ ($\log_{10}0.1$) and $-3$ ($\log_{10}0.001$).
    * Set $\beta = 1 - 10^r$.


