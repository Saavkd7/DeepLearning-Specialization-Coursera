# My Diary

Today  **Saturday, 17 Jan 2026**.

## General Counter
It has been    **153** days since I started this diary.

# Repository Counter

Day **25** From I started this repository




# Optimization Algorithm: Momentum

## 1. Executive Summary
Standard Gradient Descent has a problem: it oscillates.
If the path to the minimum looks like a narrow valley (an ellipse), standard Gradient Descent bounces back and forth up and down the steep sides (vertical oscillations) while moving very slowly toward the actual goal (horizontal progress).
**Momentum** solves this by calculating an **Exponentially Weighted Average** of the gradients. It "smooths out" the zig-zagging vertical oscillations while building up speed in the consistent horizontal direction.

## 2. The Visual Intuition

### The Problem: Oscillations (Blue Line)
Imagine you are trying to reach the red dot (minimum).
* **Vertical:** The gradient is steep, so the algorithm takes huge steps up and down. You have to lower the learning rate to stop it from diverging.
* **Horizontal:** The progress is slow.
* **Result:** A slow, zig-zagging path to the bottom.

### The Solution: Momentum (Red Line)
Momentum averages the steps.
* **Vertical:** The "up" steps and "down" steps average each other out to near zero.
* **Horizontal:** All steps point to the right, so the average builds up speed (momentum).
* **Result:** The oscillations are damped, and the algorithm shoots straight toward the minimum.


## 3. The Physics Analogy
Think of a **ball rolling down a bowl**.
* **Standard Gradient Descent:** The ball has no mass. It instantly changes direction based on the slope at the current point.
* **Momentum:** The ball has mass. It gains **Velocity** ($v$) as it rolls. Even if the surface bumps it slightly up, its momentum carries it forward.
* **Friction ($\beta$):** The parameter $\beta$ acts like friction to stop the ball from accelerating forever.

## 4. Implementation Details

### The Algorithm
On iteration $t$, compute derivatives $dW, db$ on the current mini-batch. Then update a velocity term $v$:

$$v_{dW} = \beta v_{dW} + (1 - \beta) dW$$
$$v_{db} = \beta v_{db} + (1 - \beta) db$$

Finally, update the weights using this velocity instead of the raw gradient:

$$W = W - \alpha v_{dW}$$
$$b = b - \alpha v_{db}$$


### Hyperparameters
* **$\alpha$ (Learning Rate):** Still needs tuning.
* **$\beta$ (Momentum):** Controls the smoothing.
    * **$\beta = 0.9$**: This is the industry standard. It works for almost all problems. It roughly averages the last **10 gradients**.
    * **Initialization:** Initialize $v_{dW}$ and $v_{db}$ as zeros.

## 5. Expert Nuance: Two Versions
You might see a different formula in some papers: $v_{dW} = \beta v_{dW} + dW$ (omitting the $1-\beta$).
* **Andrew Ng's Advice:** Stick to the version above (with $1-\beta$). It is more intuitive because it doesn't change the scale of the gradients, making the learning rate $\alpha$ easier to tune.
