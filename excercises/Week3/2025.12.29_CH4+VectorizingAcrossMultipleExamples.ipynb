{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19289cf9-8d3c-49a0-8a39-ce1c6109818e",
   "metadata": {},
   "source": [
    "## 5. Implementation Code\n",
    "\n",
    "Here is the Python implementation comparing the loop approach (conceptual) to the vectorized approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e7bd7bf-d0e2-4dae-883e-178493113c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (3, 5)\n",
      "Predictions shape: (1, 5)\n",
      "Successfully processed 5 examples in parallel.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def vectorized_forward_prop(X, W1, b1, W2, b2):\n",
    "    \"\"\"\n",
    "    Computes forward propagation for the entire dataset X (m examples).\n",
    "    \n",
    "    Arguments:\n",
    "    X -- Input data (n_x, m)\n",
    "    W1 -- Weights layer 1 (n_h, n_x)\n",
    "    b1 -- Bias layer 1 (n_h, 1)\n",
    "    W2 -- Weights layer 2 (n_y, n_h)\n",
    "    b2 -- Bias layer 2 (n_y, 1)\n",
    "    \n",
    "    Returns:\n",
    "    A2 -- The output predictions for all m examples (n_y, m)\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- LAYER 1 ---\n",
    "    # Matrix Multiplication: (n_h, n_x) dot (n_x, m) -> (n_h, m)\n",
    "    # Bias b1 is broadcasted to all m columns\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    \n",
    "    # Activation\n",
    "    A1 = np.tanh(Z1)\n",
    "    \n",
    "    # --- LAYER 2 ---\n",
    "    # Matrix Multiplication: (n_y, n_h) dot (n_h, m) -> (n_y, m)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    \n",
    "    # Activation (Sigmoid)\n",
    "    A2 = 1 / (1 + np.exp(-Z2))\n",
    "    \n",
    "    return A2\n",
    "\n",
    "# --- TEST ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 3 Features, 4 Hidden Units, 1 Output Unit\n",
    "    # 5 Examples (m=5)\n",
    "    X_input = np.random.randn(3, 5) \n",
    "    \n",
    "    # Initialize random parameters\n",
    "    W1 = np.random.randn(4, 3)\n",
    "    b1 = np.zeros((4, 1))\n",
    "    W2 = np.random.randn(1, 4)\n",
    "    b2 = np.zeros((1, 1))\n",
    "    \n",
    "    predictions = vectorized_forward_prop(X_input, W1, b1, W2, b2)\n",
    "    \n",
    "    print(f\"Input shape: {X_input.shape}\")      # (3, 5)\n",
    "    print(f\"Predictions shape: {predictions.shape}\") # (1, 5)\n",
    "    print(\"Successfully processed 5 examples in parallel.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3595e078-0634-4fbf-bb85-3a7895cb6073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Kev-3.11.11)",
   "language": "python",
   "name": "kev3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
