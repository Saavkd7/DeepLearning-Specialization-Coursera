{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51aad0c8-ca8b-4902-892e-00382f0781e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# VECTORIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee058d57-b78b-49e8-9158-e8cd85760dee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "*We will simulate a small batch of low-resolution images to demonstrate Vectorization.*\n",
    "\n",
    "* The goal is to transform 3D image data (Height $\\times$ Width $\\times$ Channels) into the matrix formats required for processing.\n",
    "\n",
    "1.  *Key transformation: Reshaping 3D arrays into 1D vectors.*\n",
    "\n",
    "2.  *Key conflict: You will see firsthand how the \"Theory\" notation from your transcript ($n_x, m$) conflicts with the \"Practice\" notation of Scikit-Learn/PyTorch ($m, n_x$).2.* \n",
    "\n",
    "3.  *Technical Deep Dive: The Code Scenario Setup Let's pretend we have 10 images, \n",
    "each 64x64 pixels with 3 color channels (RGB).$m = 10$$n_x = 64 \\times 64 \\times 3 = 12,288$*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b20aa6-85f3-415c-a4bf-b1854f5ce76e",
   "metadata": {},
   "source": [
    "# NUMPY EXAMPLE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1773290-1d61-4d4b-9269-aa5b08866a74",
   "metadata": {},
   "source": [
    "NumPy is used here to manually construct the matrix exactly as described in your course materials (Column-Major)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b73b35e-2fc0-4d40-91b5-062036a54a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Batch Shape: (10, 64, 64, 3)\n",
      "Single Vector Shape: (12288, 1)\n",
      "Matrix X Shape (Course Notation): (12288, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. Simulate the data: 10 images, 64x64, 3 channels\n",
    "# Random pixel values between 0-255\n",
    "images_raw = np.random.randint(0, 256, size=(10, 64, 64, 3)) \n",
    "\n",
    "print(f\"Original Batch Shape: {images_raw.shape}\") \n",
    "# Output: (10, 64, 64, 3) -> (m, height, width, channels)\n",
    "\n",
    "# 2. Unroll ONE image (The \"Sweater\" analogy)\n",
    "single_image = images_raw[0]\n",
    "# reshape(-1) tells numpy to figure out the dimension length automatically\n",
    "# reshape(-1, 1) forces it into a column vector (nx, 1)\n",
    "single_vector = single_image.reshape(-1, 1) \n",
    "\n",
    "print(f\"Single Vector Shape: {single_vector.shape}\") \n",
    "# Output: (12288, 1) -> Matches course notation x vector\n",
    "\n",
    "# 3. Vectorize the ENTIRE batch into Matrix X\n",
    "# We want shape (nx, m) -> (12288, 10)\n",
    "# Step A: Flatten the image dimensions (64*64*3)\n",
    "# Step B: Transpose (.T) to turn rows (examples) into columns\n",
    "X_theory = images_raw.reshape(images_raw.shape[0], -1).T\n",
    "\n",
    "print(f\"Matrix X Shape (Course Notation): {X_theory.shape}\")\n",
    "# Output: (12288, 10) -> (Features, Examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61b69b7e-6844-432e-84a9-cc197655798b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 58, 207,  42],\n",
       "         [244, 210, 172],\n",
       "         [122,  52,  31],\n",
       "         ...,\n",
       "         [ 38,  99,  31],\n",
       "         [232,  67,  23],\n",
       "         [137, 104, 140]],\n",
       "\n",
       "        [[190, 171, 156],\n",
       "         [ 17,  42,  57],\n",
       "         [158,  77, 134],\n",
       "         ...,\n",
       "         [184,  50, 150],\n",
       "         [219, 101, 146],\n",
       "         [ 84,  78,  72]],\n",
       "\n",
       "        [[203, 183, 100],\n",
       "         [150,   4,  98],\n",
       "         [ 62,  11,   3],\n",
       "         ...,\n",
       "         [230, 169, 251],\n",
       "         [210,  27, 186],\n",
       "         [ 45, 113,  84]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[145,  93, 241],\n",
       "         [217,   9, 107],\n",
       "         [245,  33,  40],\n",
       "         ...,\n",
       "         [134,  95, 143],\n",
       "         [206, 242,  43],\n",
       "         [153, 200,  61]],\n",
       "\n",
       "        [[142, 166, 254],\n",
       "         [140, 225, 159],\n",
       "         [163, 110,  73],\n",
       "         ...,\n",
       "         [ 45, 206,   5],\n",
       "         [ 64, 240,  68],\n",
       "         [225,  21, 177]],\n",
       "\n",
       "        [[194, 109, 114],\n",
       "         [ 13, 238, 240],\n",
       "         [150, 174,  13],\n",
       "         ...,\n",
       "         [ 26, 172, 234],\n",
       "         [ 37, 226, 139],\n",
       "         [198, 250,  68]]],\n",
       "\n",
       "\n",
       "       [[[ 92, 228, 184],\n",
       "         [ 38,  76, 193],\n",
       "         [ 87, 229, 243],\n",
       "         ...,\n",
       "         [177, 204,   3],\n",
       "         [ 85, 164,   3],\n",
       "         [ 31,  11,  87]],\n",
       "\n",
       "        [[211, 194, 128],\n",
       "         [106,  78, 189],\n",
       "         [151,  73,  15],\n",
       "         ...,\n",
       "         [ 23, 134, 109],\n",
       "         [ 18, 138, 106],\n",
       "         [ 60, 238,  78]],\n",
       "\n",
       "        [[110,  87,  17],\n",
       "         [211, 230, 195],\n",
       "         [ 39, 237,  49],\n",
       "         ...,\n",
       "         [254, 105, 243],\n",
       "         [ 41, 125,   6],\n",
       "         [246,  24, 209]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 69,  64, 135],\n",
       "         [221, 199,  40],\n",
       "         [ 26, 161, 254],\n",
       "         ...,\n",
       "         [230, 201,  72],\n",
       "         [ 81,  86,  21],\n",
       "         [ 23, 209,  49]],\n",
       "\n",
       "        [[255,   5, 207],\n",
       "         [121,  88, 132],\n",
       "         [112, 104, 248],\n",
       "         ...,\n",
       "         [227,  19, 120],\n",
       "         [216, 185, 183],\n",
       "         [  0,  90, 162]],\n",
       "\n",
       "        [[238,  94, 115],\n",
       "         [ 12, 176, 212],\n",
       "         [120,  29, 140],\n",
       "         ...,\n",
       "         [ 84,  25,  51],\n",
       "         [155,  74,  56],\n",
       "         [121, 161,  16]]],\n",
       "\n",
       "\n",
       "       [[[127, 107, 227],\n",
       "         [250,  44, 195],\n",
       "         [156, 238, 154],\n",
       "         ...,\n",
       "         [ 37,   8,  89],\n",
       "         [243, 253,  31],\n",
       "         [111, 114,  93]],\n",
       "\n",
       "        [[ 98, 247, 157],\n",
       "         [103,  93,   2],\n",
       "         [  0,  64, 136],\n",
       "         ...,\n",
       "         [105,  47, 135],\n",
       "         [164,  61, 122],\n",
       "         [ 25, 201,  37]],\n",
       "\n",
       "        [[ 73,  20, 209],\n",
       "         [247, 100,  46],\n",
       "         [235, 183,  38],\n",
       "         ...,\n",
       "         [154,  54, 156],\n",
       "         [132, 226, 104],\n",
       "         [147, 172,  24]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[140,  54, 229],\n",
       "         [255,  74,  48],\n",
       "         [ 34, 237,  91],\n",
       "         ...,\n",
       "         [199, 132,  85],\n",
       "         [ 28, 135, 182],\n",
       "         [216,  78, 141]],\n",
       "\n",
       "        [[ 40, 225, 207],\n",
       "         [102, 214,  55],\n",
       "         [199, 174, 107],\n",
       "         ...,\n",
       "         [211, 124,  15],\n",
       "         [ 30, 255,  62],\n",
       "         [208, 179,  87]],\n",
       "\n",
       "        [[ 39, 133, 169],\n",
       "         [226, 167,  78],\n",
       "         [237, 113, 115],\n",
       "         ...,\n",
       "         [183, 240, 121],\n",
       "         [ 31,  41, 173],\n",
       "         [ 43, 104,  46]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 73, 219, 123],\n",
       "         [124, 211, 218],\n",
       "         [246, 226,  25],\n",
       "         ...,\n",
       "         [ 88, 196, 158],\n",
       "         [211,  25, 198],\n",
       "         [ 99, 144,  15]],\n",
       "\n",
       "        [[196, 110, 216],\n",
       "         [ 36, 171,   8],\n",
       "         [101, 170, 169],\n",
       "         ...,\n",
       "         [132,  90, 138],\n",
       "         [ 27, 116,  36],\n",
       "         [ 94, 158, 195]],\n",
       "\n",
       "        [[247, 216, 190],\n",
       "         [ 11, 101, 136],\n",
       "         [171,   6, 167],\n",
       "         ...,\n",
       "         [ 24, 114,   8],\n",
       "         [  1,  56, 190],\n",
       "         [ 25,  25, 232]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[134, 157, 160],\n",
       "         [165,  84, 214],\n",
       "         [211,  58, 160],\n",
       "         ...,\n",
       "         [161,  81, 120],\n",
       "         [ 93, 198, 193],\n",
       "         [178, 162, 241]],\n",
       "\n",
       "        [[ 64, 196, 236],\n",
       "         [ 91, 248, 111],\n",
       "         [231,  11,  42],\n",
       "         ...,\n",
       "         [180,  58,  95],\n",
       "         [ 87, 215,  77],\n",
       "         [249, 139,  16]],\n",
       "\n",
       "        [[ 98,  33, 154],\n",
       "         [100,  30, 211],\n",
       "         [211,  55, 237],\n",
       "         ...,\n",
       "         [214,  31, 141],\n",
       "         [103, 205, 148],\n",
       "         [ 78,   6, 197]]],\n",
       "\n",
       "\n",
       "       [[[183, 105, 175],\n",
       "         [237, 134,  26],\n",
       "         [195, 121,  15],\n",
       "         ...,\n",
       "         [145, 202, 193],\n",
       "         [117, 234,  98],\n",
       "         [243, 213,  15]],\n",
       "\n",
       "        [[147, 109, 184],\n",
       "         [247,  54, 161],\n",
       "         [ 30,  19,  71],\n",
       "         ...,\n",
       "         [ 99, 157, 128],\n",
       "         [ 39, 184, 224],\n",
       "         [136, 154,  56]],\n",
       "\n",
       "        [[ 65, 105,   6],\n",
       "         [166,  44, 182],\n",
       "         [ 30, 141,  22],\n",
       "         ...,\n",
       "         [ 20, 199, 135],\n",
       "         [161, 219, 242],\n",
       "         [212, 219, 234]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 10, 216,  68],\n",
       "         [222, 212, 115],\n",
       "         [204, 252, 153],\n",
       "         ...,\n",
       "         [134,  72, 109],\n",
       "         [ 30, 226, 191],\n",
       "         [163,  53, 176]],\n",
       "\n",
       "        [[204, 147, 213],\n",
       "         [194,  34, 190],\n",
       "         [144, 104, 218],\n",
       "         ...,\n",
       "         [225, 128,  47],\n",
       "         [103, 162,   1],\n",
       "         [158, 140, 239]],\n",
       "\n",
       "        [[192,  73, 124],\n",
       "         [247, 163,  92],\n",
       "         [193, 215,  50],\n",
       "         ...,\n",
       "         [ 79,  99, 129],\n",
       "         [ 53, 204,  82],\n",
       "         [ 44, 116,  78]]],\n",
       "\n",
       "\n",
       "       [[[129,  77,  82],\n",
       "         [ 74,  69, 137],\n",
       "         [ 69, 242, 161],\n",
       "         ...,\n",
       "         [117, 158, 212],\n",
       "         [117, 241, 101],\n",
       "         [208,  24,  72]],\n",
       "\n",
       "        [[165,  57,  45],\n",
       "         [135,  52,  71],\n",
       "         [109,  17,  39],\n",
       "         ...,\n",
       "         [ 93, 161,   4],\n",
       "         [111, 180, 201],\n",
       "         [234, 252, 226]],\n",
       "\n",
       "        [[202,  96, 180],\n",
       "         [168, 144,   5],\n",
       "         [ 29, 173, 235],\n",
       "         ...,\n",
       "         [213,  49, 112],\n",
       "         [ 59, 197, 255],\n",
       "         [117,  27,  44]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[123, 183, 161],\n",
       "         [ 27,  31,  92],\n",
       "         [  9, 185, 207],\n",
       "         ...,\n",
       "         [ 45,  97, 110],\n",
       "         [101,  94,  42],\n",
       "         [ 70,  23, 175]],\n",
       "\n",
       "        [[ 81, 133, 231],\n",
       "         [227,  92, 229],\n",
       "         [ 62, 177, 220],\n",
       "         ...,\n",
       "         [188, 215, 222],\n",
       "         [206, 191, 243],\n",
       "         [151, 217, 146]],\n",
       "\n",
       "        [[179, 227, 203],\n",
       "         [ 87, 206,  97],\n",
       "         [170,   8, 174],\n",
       "         ...,\n",
       "         [248,  54, 102],\n",
       "         [111,  23, 183],\n",
       "         [166, 139,  18]]]], shape=(10, 64, 64, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d26cbb5-0aaa-4178-9716-c078bf22f6e6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# TORCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ec8b00-807e-48b0-a2b9-ea7831aa29db",
   "metadata": {},
   "source": [
    "PyTorch is built for GPUs. It prefers keeping the Batch Dimension ($m$) as the first dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcd7c8a7-0d4d-41ab-9786-271b0f817324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Input Shape: torch.Size([10, 12288])\n",
      "PyTorch Shape (Transposed to match theory): torch.Size([12288, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1. Convert NumPy data to PyTorch Tensor\n",
    "# PyTorch images are usually (Batch, Channels, Height, Width), but we'll stick to our raw input\n",
    "tensor_images = torch.tensor(images_raw, dtype=torch.float32)\n",
    "\n",
    "# 2. The \"Flatten\" Operation\n",
    "# start_dim=1 means: Keep dim 0 (the batch of 10) intact, flatten everything else.\n",
    "X_pytorch = torch.flatten(tensor_images, start_dim=1)\n",
    "\n",
    "print(f\"PyTorch Input Shape: {X_pytorch.shape}\")\n",
    "# Output: (10, 12288) -> (Batch, Features)\n",
    "\n",
    "# NOTE: This is the OPPOSITE of your transcript.\n",
    "# To force it to match your transcript (for math operations):\n",
    "X_pytorch_transposed = X_pytorch.T\n",
    "print(f\"PyTorch Shape (Transposed to match theory): {X_pytorch_transposed.shape}\")\n",
    "# Output: (12288, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2273182-3b0b-49df-9f63-b856639b5a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 58.,  92., 127.,  ...,  73., 183., 129.],\n",
       "        [207., 228., 107.,  ..., 219., 105.,  77.],\n",
       "        [ 42., 184., 227.,  ..., 123., 175.,  82.],\n",
       "        ...,\n",
       "        [198., 121.,  43.,  ...,  78.,  44., 166.],\n",
       "        [250., 161., 104.,  ...,   6., 116., 139.],\n",
       "        [ 68.,  16.,  46.,  ..., 197.,  78.,  18.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pytorch_transposed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0587ae74-25b5-4919-9cd4-9205a21c1269",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Scikit-Learn (The Classic ML Standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d84f07-0513-4057-9147-ebd478e2221c",
   "metadata": {},
   "source": [
    "Scikit-Learn strictly enforces $(Samples, Features)$. It will often throw an error if you provide $(Features, Samples)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "102b7f4c-f9de-4534-9dc3-7d2af0b576eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-Learn model trained successfully on (Batch, Features) format.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Scikit-Learn expects X to be (n_samples, n_features)\n",
    "X_sklearn = images_raw.reshape(10, -1) # Shape: (10, 12288)\n",
    "Y_labels = np.random.randint(0, 2, size=(10,)) # Binary labels\n",
    "\n",
    "# Initialize model\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# If we tried passing X_theory (12288, 10), this would CRASH.\n",
    "# We must pass the row-major format:\n",
    "clf.fit(X_sklearn, Y_labels)\n",
    "\n",
    "print(\"Scikit-Learn model trained successfully on (Batch, Features) format.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bed8b8e-4a04-4de7-a989-545364f3c673",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# EXPERT NOTES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fd0185-700c-4d37-81d7-ce92a8a3b0d7",
   "metadata": {},
   "source": [
    "## Vectorization Framework Comparison: NumPy vs. Scikit-Learn vs. PyTorch\n",
    "\n",
    "### 1. Executive Summary\n",
    "\"Vectorization\" refers to processing an entire batch of data (Matrix $X$) simultaneously rather than looping through examples one by one.\n",
    "\n",
    "* **NumPy** is the **Fundamental Choice**: It is the best tool for *understanding* the linear algebra (like in your current course), but it is limited to the CPU.\n",
    "* **Scikit-Learn** is the **Classic Choice**: It abstracts vectorization away completely. You don't write the matrix math; you just call `.fit()`. It is excellent for traditional ML (SVMs, Random Forests) but insufficient for custom Deep Learning.\n",
    "* **PyTorch** is the **Optimal Choice for Deep Learning**: It mimics NumPy's syntax but adds two superpowers: **GPU Acceleration** (parallel processing) and **Autograd** (calculating gradients automatically).\n",
    "\n",
    "**Verdict:** For learning the *mechanics* (now), use **NumPy**. For building *production Neural Networks* (later), **PyTorch** is strictly superior.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Technical Deep Dive: The Comparison Matrix\n",
    "\n",
    "| Feature | **NumPy** | **Scikit-Learn** | **PyTorch** |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Primary Role** | Numerical Computing & Linear Algebra | Traditional Machine Learning Algorithms | Deep Learning & Tensor Computation |\n",
    "| **Hardware** | **CPU Only** (Serial/SIMD) | **CPU Only** (mostly) | **GPU & TPU** (Massive Parallelism) |\n",
    "| **Vectorization** | Manual (You write `np.dot`) | Hidden (Internally optimized) | Manual (You write `torch.matmul`) |\n",
    "| **Gradients** | Manual (You write the derivatives) | N/A (Handled internally) | **Automatic** (Autograd engine) |\n",
    "| **Data Shape** | Agnostic (Row or Column major) | Strict Row-Major $(m, n_x)$ | Agnostic (Prefer Batch-First) |\n",
    "| **Best For** | Prototyping, Data Cleaning, Math Theory | Quick Baselines (Logistic Reg, SVM) | **Training Neural Networks** |\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Analysis: When to Use Which?\n",
    "\n",
    "###  A. NumPy: \"The Whiteboard Simulator\"\n",
    "**Use this when:** You are learning the math (like in this module) or preprocessing data.\n",
    "* **Why:** NumPy forces you to define the dimensions exactly as you write them in LaTeX equations ($Z = WX + b$). It is lightweight and installed everywhere.\n",
    "* **Limit:** It cannot run on a Graphics Card (GPU). If you try to vectorize 1 million images in NumPy, your CPU will choke.\n",
    "\n",
    "### B. Scikit-Learn: \"The Black Box\"\n",
    "**Use this when:** You need a quick baseline result or are doing non-neural ML (e.g., Random Forest).\n",
    "* **Why:** It handles the vectorization internally. You don't need to initialize weights or define forward propagation.\n",
    "* **Limit:** It is too rigid for Deep Learning. You cannot easily change the architecture (e.g., adding a specific \"Skip Connection\" or changing activation functions layer-by-layer). It also focuses on row-major data $(m, n_x)$, which conflicts with your current course notation.\n",
    "\n",
    "### C. PyTorch: \"The Heavy Lifter\"\n",
    "**Use this when:** You are training Deep Learning models.\n",
    "* **Why:** It is essentially \"NumPy for GPUs.\"\n",
    "    1.  **Speed:** Matrix multiplication on a GPU is $100\\times$ faster than a CPU for large matrices.\n",
    "    2.  **Autograd:** You write the Forward Pass, and PyTorch *automatically* calculates the Backward Pass (gradients). In NumPy, you have to hand-derive the calculus for backprop.\n",
    "* **Limit:** It has a slightly higher learning curve and stricter type checking (e.g., `float32` vs `float64`).\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Performance Benchmark (The \"Why\")\n",
    "\n",
    "Imagine vectorizing the dot product $Z = WX$ for a massive layer.\n",
    "\n",
    "* **Matrix Sizes:** $W$ is $(1000 \\times 1000)$, $X$ is $(1000 \\times 10000)$.\n",
    "* **Operation:** Matrix Multiplication.\n",
    "\n",
    "1.  **NumPy (CPU):**\n",
    "    * The CPU processes this sequentially or with limited parallelism (SIMD).\n",
    "    * *Time:* ~0.5 seconds.\n",
    "2.  **PyTorch (GPU):**\n",
    "    * The GPU has thousands of cores. It breaks the matrix into tiny tiles and computes them all at the exact same instant.\n",
    "    * *Time:* ~0.005 seconds.\n",
    "\n",
    "**Conclusion:** PyTorch is **orders of magnitude more optimal** for the specific vectorization required in Deep Learning.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Expert Nuance: The \"Ecosystem\" Workflow\n",
    "\n",
    "Expert Data Scientists rarely choose *just* one. We use them in a specific pipeline:\n",
    "\n",
    "1.  **NumPy:** Used to load raw data, reshape it, and normalize it (Data Preprocessing).\n",
    "2.  **PyTorch:** The NumPy array is converted to a PyTorch Tensor (`torch.from_numpy()`). The Tensor is moved to the GPU (`.to('cuda')`) for the heavy vectorization and training.\n",
    "3.  **Scikit-Learn:** Used afterwards to calculate metrics like Confusion Matrices or F1-Scores on the predictions.\n",
    "\n",
    "**Recommendation:** Stick to **NumPy** for this specific week of your course to master the algebra. Switch to **PyTorch** as soon as you start building networks deeper than 2 layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd8a2fd-d227-474c-9f0f-02808d41d35b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Kev-3.11.11)",
   "language": "python",
   "name": "kev3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
