# My Diary

Today  **{{DATE_PRETTY}}**.

## General Counter
It has been    **{{DAY_SINCE_2025_08_18}}** days since I started this diary.

# Repository Counter

Day **{{DAYS_SINCE_REPO_START}}** From I started this repository

# CNN Basics: Strided Convolutions

## 1. What is Stride?
So far, we have slid the filter over the image one pixel at a time (Stride $s=1$).
**Strided Convolution** means skipping pixels. If $s=2$, the filter "hops" 2 pixels at a time.

### Example:
* **Input:** $7 \times 7$ Image.
* **Filter:** $3 \times 3$.
* **Stride ($s$):** 2.

**The Process:**
1.  **Position 1:** Top-left corner. Perform element-wise product and sum $\rightarrow$ Result: 91.
2.  **Position 2:** Hop **2 steps** to the right. Perform product and sum $\rightarrow$ Result: 100.
3.  **Position 3:** Hop **2 steps** again. Perform product and sum $\rightarrow$ Result: 83.
4.  **Next Row:** Hop **2 steps** down and repeat.

* **Result:** Instead of a $5 \times 5$ output (which you'd get with $s=1$), you get a **$3 \times 3$ output**. This effectively "downsamples" or shrinks the image.


## 2. The General Formula
To calculate the output size of any convolution layer, use this universal formula:

$$\text{Output Size} = \lfloor \frac{n + 2p - f}{s} + 1 \rfloor \times \lfloor \frac{n + 2p - f}{s} + 1 \rfloor$$

* $n$: Input size (e.g., 7)
* $p$: Padding (e.g., 0)
* $f$: Filter size (e.g., 3)
* $s$: Stride (e.g., 2)
* $\lfloor ... \rfloor$: **Floor** operation (round down). If the filter doesn't fit perfectly inside the image (or padded image), we drop the parts that hang over the edge.

**Check the Math for the Example:**
$$\lfloor \frac{7 + 0 - 3}{2} + 1 \rfloor = \lfloor \frac{4}{2} + 1 \rfloor = \lfloor 2 + 1 \rfloor = 3$$
Output is $3 \times 3$.


## 3. Technical Note: Convolution vs. Cross-Correlation
There is a slight terminology inconsistency between Deep Learning and Math/Signal Processing.

* **Strict Math Definition:** To perform a "Convolution" $(A * B)$, you must first **flip** (mirror) the filter both horizontally and vertically, and *then* slide it over the image. This property (Associativity) is useful in signal processing.
* **Deep Learning Convention:** We **skip the flipping step**. We just slide the filter as is.
    * *Technically:* This is called **Cross-Correlation**.
    * *Practically:* In Deep Learning, we call it **Convolution** anyway. Since the filter weights ($w$) are learned parameters, the network can simply "learn" the flipped version if that's what works best. It simplifies the code and math.
    
## 4 Implementation 

import numpy as np

def simple_stride_conv(img, kernel, s):
    # n: entrada, f: filtro, s: stride
    n = img.shape[0]
    f = kernel.shape[0]
    
    # Tamaño de salida: (n - f) / s + 1
    out_size = (n - f) // s + 1
    output = np.zeros((out_size, out_size))

    for i in range(out_size):
        for j in range(out_size):
            # El truco: multiplicamos el índice por el stride (i * s)
            region = img[i*s : i*s+f, j*s : j*s+f]
            output[i, j] = np.sum(region * kernel)
            
    return output

# 5 Ejemplo rápido: Imagen 5x5, Filtro 3x3, Stride 2 -> Salida 2x2
img = np.ones((5, 5))
kernel = np.ones((3, 3))
print(simple_stride_conv(img, kernel, s=2))
