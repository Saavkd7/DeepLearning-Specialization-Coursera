# My Diary

Today  **{{DATE_PRETTY}}**.

## General Counter
It has been    **{{DAY_SINCE_2025_08_18}}** days since I started this diary.

# Repository Counter

Day **{{DAYS_SINCE_REPO_START}}** From I started this repository

# CNN Basics: Pooling Layers

## 1. What is Pooling?
Pooling layers are used to reduce the spatial dimensions (Height and Width) of the input volume. This reduces the amount of computation required and makes the network more robust to small variations in the position of features.

### Max Pooling (Most Common)
Break the input into regions and output the **maximum value** from each region.

**Example:**
* **Input:** $4 \times 4$ matrix.
* **Hyperparameters:** $f=2$ (Filter size), $s=2$ (Stride).
* **Process:**
    1.  Look at the top-left $2 \times 2$ region. Max value is **9**.
    2.  Stride 2 steps right. Look at top-right $2 \times 2$. Max is **2**.
    3.  Stride 2 steps down. Look at bottom-left $2 \times 2$. Max is **6**.
    4.  Stride 2 steps right. Look at bottom-right $2 \times 2$. Max is **3**.
* **Output:** A $2 \times 2$ matrix containing $[9, 2; 6, 3]$.


## 2. Why Max Pooling? (Intuition)
If a large number represents the detection of a specific feature (like a vertical edge or an eye):
* **Preservation:** Max pooling asks, "Did I find this feature *anywhere* in this $2 \times 2$ region?"
* **Robustness:** If the feature (high value) shifts slightly to the left or right, it still stays in the max pooling window, so the output remains the same. This makes the detector invariant to small translations.

## 3. Average Pooling
Instead of the maximum, you calculate the **average** of the numbers in the window.
* This is used less frequently today, except sometimes very deep in the network to collapse a $7 \times 7$ volume down to $1 \times 1$.


## 4. Hyperparameters & Formulas
Pooling layers have hyperparameters but **NO learnable parameters** (no weights $W$ or bias $b$). Gradient descent does not change anything here.

* **Hyperparameters:**
    * $f$: Filter size (Common: $f=2$ or $f=3$).
    * $s$: Stride (Common: $s=2$).
    * $p$: Padding (Almost always $p=0$).
    * Type: Max or Average.

* **Dimensions:**
    * Input: $n_H \times n_W \times n_C$.
    * Output: $\lfloor \frac{n_H - f}{s} + 1 \rfloor \times \lfloor \frac{n_W - f}{s} + 1 \rfloor \times n_C$.
    * *Note:* Pooling applies to every channel **independently**. The depth ($n_C$) remains unchanged.


## 5. Relation to Earlier Concepts
* **Strided Convolutions:** Both Pooling and Strided Convolutions downsample the image (reduce $H$ and $W$). The difference is that Pooling is a fixed mathematical function (max/avg), whereas Strided Convolution is a learnable linear operation followed by a non-linearity.
* **Feature Maps:** In the previous section, we saw how a Conv layer outputs a volume of features. Pooling takes that volume and "summarizes" it, keeping the most important activations (high values) while discarding precise spatial details.

## 6. Basic Chunk Implementation
Here is the core logic for Max Pooling on a single 2D slice:

```python
import numpy as np

def max_pool_single_step(a_slice_prev):
    """
    Apply max pooling to a single slice (region) of the input.
    """
    # Just take the max of the numpy array slice
    return np.max(a_slice_prev)

# Test
region = np.array([[1, 3], [2, 9]])
print(f"Max of region: {max_pool_single_step(region)}") # Output: 9
