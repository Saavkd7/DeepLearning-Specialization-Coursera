# My Diary

Today  **Monday, 19 Jan 2026**.

## General Counter
It has been    **155** days since I started this diary.

# Repository Counter

Day **27** From I started this repository

# Convolutional Sliding Windows

## 1. The Problem with Standard Sliding Windows
As we saw, running a ConvNet sequentially on thousands of cropped regions is too slow.
* **Redundancy:** When you slide the window just a few pixels, the new region overlaps heavily with the old one. The network re-computes features for the same pixels over and over.
* **Solution:** We want to run the ConvNet *once* on the entire image and get predictions for all possible window positions simultaneously.

## 2. Step 1: Turning FC Layers into Conv Layers
To apply a network to a larger image than it was trained on, we must remove the fixed-size **Fully Connected (FC)** layers.

* **Standard FC Layer:**
    * Input: $5 \times 5 \times 16$.
    * Operation: Flatten to vector, then multiply by matrix (400 neurons).
    * Output: Vector of size 400.
    * *Limitation:* Input *must* be $5 \times 5$. If the image is bigger, this crashes.

* **Convolutional FC Layer:**
    * Input: $5 \times 5 \times 16$.
    * Operation: Convolve with **400 filters** of size $5 \times 5$.
    * Output: $1 \times 1 \times 400$ volume.
    * *Magic:* Mathematically, this gives the exact same result as the FC layer, but it is now a **Convolution**. Because it's a convolution, if the input is bigger (e.g., $6 \times 6$), the output just becomes bigger (e.g., $2 \times 2$) instead of crashing.


## 3. Step 2: The Convolutional Implementation
Once the network is **Fully Convolutional** (FCN), we can feed in the entire large image at once.

* **Scenario:**
    * **Training:** Trained on small $14 \times 14$ images. Output is $1 \times 1 \times 4$.
    * **Testing:** Input a large $28 \times 28$ image.
* **Process:**
    * Instead of cropping, just feed the $28 \times 28$ image into the FCN.
    * The computations ripple through the layers.
    * **Final Output:** Instead of a single $1 \times 1 \times 4$ prediction, you get an **$8 \times 8 \times 4$ volume**.
* **Interpretation:** Each of the 64 cells $(8 \times 8)$ in the output corresponds to the prediction for a specific window position in the input image.
    * Top-left cell = Prediction for the top-left sliding window.
    * Bottom-right cell = Prediction for the bottom-right sliding window.
* **Benefit:** You computed 64 sliding window predictions in **one single forward pass**, sharing all the common computation pixels.


## 4. Relation to Earlier Concepts
* **Valid/Same Convolutions:** The math follows the standard formula $n_{out} = \frac{n_{in} - f}{s} + 1$. Because we don't flatten, the spatial dimensions $(n_H, n_W)$ are preserved and propagated to the end.
* **1x1 Convolutions:** The final layers often use $1 \times 1$ convolutions to act as "pixel-wise" fully connected layers, mapping the deep features to the 4 output classes ($y$) for every location in the grid.

## 5. Basic Chunk Implementation (FC to Conv)
This snippet shows how to convert a standard dense layer into a convolutional layer in PyTorch.

```python
import torch
import torch.nn as nn

def convert_fc_to_conv():
    # Simulate an input volume of 5x5x16
    input_vol = torch.randn(1, 16, 5, 5) 
    
    # 1. Standard Way (Conceptual): Flatten -> Linear
    # flattening would give 16*5*5 = 400 inputs
    fc_layer = nn.Linear(400, 400) 
    
    # 2. Convolutional Way: Filter size matches input size (5x5)
    # in_channels=16, out_channels=400, kernel_size=5
    conv_layer = nn.Conv2d(16, 400, kernel_size=5)
    
    # Forward pass
    output = conv_layer(input_vol)
    
    # Output shape is (1, 400, 1, 1) -> Same data content as a vector of 400
    print(f"Conv Output Shape: {output.shape}")
    
    # BONUS: What if input is bigger? (e.g., 6x6 sliding window simulation)
    larger_input = torch.randn(1, 16, 6, 6)
    larger_output = conv_layer(larger_input)
    # Output is now 2x2! (4 predictions at once)
    print(f"Larger Input Output: {larger_output.shape}")

convert_fc_to_conv()


