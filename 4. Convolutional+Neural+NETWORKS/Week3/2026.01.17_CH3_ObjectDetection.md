# My Diary

Today  **{{DATE_PRETTY}}**.

## General Counter
It has been    **{{DAY_SINCE_2025_08_18}}** days since I started this diary.

# Repository Counter

Day **{{DAYS_SINCE_REPO_START}}** From I started this repository

# Sliding Windows Object Detection

## 1. The Basic Idea
How do you detect a car if you don't know *where* it is or *how big* it is?
You use a **Sliding Window**:
1.  **Train a Classifier:** First, train a ConvNet on tightly cropped images of cars (and non-cars). The input $x$ is just the object, the output $y$ is 0 or 1.
2.  **Slide a Window:**
    * Pick a window size (e.g., small square).
    * Crop that region from the top-left of the image.
    * Feed it to the ConvNet. Is it a car?
    * Slide the window slightly to the right (stride) and repeat.
3.  **Scale Up:** Once you finish the whole image with small windows, repeat the process with **larger windows** to find larger cars.


## 2. The Problem: Computational Cost
This method is incredibly expensive computationally.
* **Brute Force:** You are running the *entire* ConvNet thousands of times for a single image (once for every crop at every scale).
* **Stride Trade-off:**
    * **Large Stride:** Faster, but you might skip over the car or get a bad bounding box.
    * **Small Stride:** Accurate localization, but prohibitively slow.

## 3. The Solution (Preview)
In the era of simple linear classifiers, this was acceptable. With deep ConvNets, it's too slow.
The solution (discussed next) is to implement this **convolutionally**. Instead of running the network sequentially on cropped regions, we can run it on the *entire* image at once to get all predictions simultaneously.

## 4. Relation to Earlier Concepts
* **Image Classification:** Sliding windows literally just runs standard image classification (Is this a car?) repeatedly. It converts a classification problem into a detection problem via brute force.
* **Stride:** Just like we used stride in convolution layers to skip pixels, we use stride here to skip window positions.

## 5. Basic Chunk Implementation (Conceptual Loop)
This snippet shows the inefficient "Brute Force" logic of sliding windows.

```python
def sliding_window_detection(image, model, window_size, stride):
    h, w = image.shape[:2]
    # Loop over every position
    for y in range(0, h - window_size, stride):
        for x in range(0, w - window_size, stride):
            # 1. Crop
            window = image[y:y+window_size, x:x+window_size]
            
            # 2. Predict (Expensive part!)
            prediction = model(window)
            
            if prediction == 1:
                print(f"Car detected at {x}, {y}")
