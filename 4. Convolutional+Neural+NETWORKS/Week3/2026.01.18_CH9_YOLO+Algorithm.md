# My Diary

Today  **Monday, 19 Jan 2026**.

## General Counter
It has been    **155** days since I started this diary.

# Repository Counter

Day **27** From I started this repository

# The YOLO Algorithm: Putting It All Together

## 1. Constructing the Training Set
To train the YOLO algorithm, we must format our target labels ($y$) correctly for every grid cell.

* **Inputs:**
    * Image (e.g., $100 \times 100 \times 3$).
    * Grid size $S \times S$ (e.g., $3 \times 3$).
    * Number of Anchors $B$ (e.g., 2).
    * Number of Classes $C$ (e.g., 3: Pedestrian, Car, Motorcycle).
* **Target Output ($y$) Dimensions:**
    * $S \times S \times (B \times (5 + C))$
    * For $3 \times 3$ grid, 2 anchors, 3 classes: $3 \times 3 \times (2 \times 8) = 3 \times 3 \times 16$.

**Label Assignment Logic:**
1.  For each object in the image, find its **midpoint**.
2.  Assign the object to the specific **grid cell** containing the midpoint.
3.  Compare the object's shape (IoU) with the two Anchor Boxes.
4.  Assign the object to the **Anchor Box** (1 or 2) with the highest IoU.
5.  Set the target vector for that specific (Grid Cell, Anchor) slot:
    * $p_c = 1$
    * $b_x, b_y, b_h, b_w$ (relative coordinates)
    * $c_1, c_2, c_3$ (one-hot encoding).


## 2. Making Predictions
Once trained, the network outputs a large volume of predictions in a single forward pass.
* **Input:** Test Image.
* **Output:** $3 \times 3 \times 2 \times 8$ volume.
* **Interpretation:** For *every* grid cell, the network predicts 2 bounding boxes (one for each anchor).
    * Many of these will have low confidence ($p_c \approx 0$).
    * Some will have high confidence ($p_c \approx 1$).


## 3. Post-Processing (The Cleanup)
The raw output contains too many boxes. We clean it up using:

1.  **Thresholding:** Discard all boxes with low probability (e.g., $p_c < 0.6$).
2.  **Non-max Suppression (NMS):**
    * **Per Class:** Run NMS independently for "Pedestrians", then "Cars", then "Motorcycles".
    * **Action:** For each class, pick the highest probability box, suppress overlapping duplicates (high IoU), and repeat.
* **Final Result:** A clean set of unique bounding boxes around the detected objects.


## 4. Relation to Earlier Concepts
* **End-to-End Learning:** We don't have separate "localization" and "classification" steps in the pipeline. We train one giant ConvNet to map `Image -> Volume`, and the "detection" emerges naturally from interpreting that volume.
* **Efficiency:** The entire process (except NMS) happens on the GPU in a single pass, making it incredibly fast.

## 5. Basic Chunk Implementation (YOLO Loss - Conceptual)
The loss function for YOLO is complex because it combines classification, regression, and confidence losses.

```python
def yolo_loss_conceptual(y_pred, y_true):
    """
    Conceptual breakdown of the YOLO loss function.
    """
    # 1. Localization Loss (MSE)
    # Only penalized if object is present (y_true.pc = 1)
    # Penalizes error in x, y, sqrt(w), sqrt(h)
    loc_loss = mse(y_pred.coords, y_true.coords) * object_mask
    
    # 2. Confidence Loss (Binary Cross Entropy / MSE)
    # Penalizes if network says "Object" when there is none
    # AND if it says "No Object" when there is one
    conf_loss = mse(y_pred.pc, y_true.pc)
    
    # 3. Classification Loss (Cross Entropy)
    # Only penalized if object is present
    class_loss = cross_entropy(y_pred.classes, y_true.classes) * object_mask
    
    return loc_loss + conf_loss + class_loss
