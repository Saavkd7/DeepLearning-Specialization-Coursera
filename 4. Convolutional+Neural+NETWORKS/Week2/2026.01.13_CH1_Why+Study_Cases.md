# My Diary

Today  **Saturday, 17 Jan 2026**.

## General Counter
It has been    **153** days since I started this diary.

# Repository Counter

Day **25** From I started this repository

# CNN Case Studies: Introduction

## 1. Why look at Case Studies?
Just as learning to write code involves reading other people's code, learning to build effective ConvNets involves reading and understanding established architectures.
* **Intuition:** Seeing how others combine Conv, Pool, and FC layers helps you gain intuition for your own designs.
* **Transferability:** An architecture that works well for one computer vision task (e.g., Cat vs. Dog) often works well for others (e.g., Self-Driving Cars).
* **Research Literacy:** Mastering these examples allows you to read and understand computer vision research papers.

## 2. The Outline of Architectures
We will analyze the following classic and modern networks:

1.  **Classic Networks:**
    * **LeNet-5:** (1998) foundational work by Yann LeCun.
    * **AlexNet:** (2012) The network that started the Deep Learning revolution.
    * **VGG:** Known for its simplicity and depth (VGG-16, VGG-19).
2.  **ResNet (Residual Networks):**
    * Introduced "Skip Connections."
    * Allowed training of extremely deep networks (e.g., **152 layers**).
3.  **Inception:**
    * Uses a unique "Inception Module" architecture.

## 3. Relation to Earlier Concepts
* **Building Blocks vs. Architecture:**
    * *Last Week:* We learned the individual "LEGO bricks" (Convolution, Padding, Stride, Pooling, FC).
    * *This Week:* We learn how to assemble those bricks into specific "Castles" (Architectures).
* **Parameter Sharing:** We will see how these architectures utilize the parameter sharing and sparsity concepts discussed previously to scale up to millions of images.

## 4. Basic Chunk Implementation
In modern Deep Learning, you rarely build these complex architectures from scratch. You often load them from a library. Here is how you might instantiate a **ResNet** (mentioned in the transcript) using Python/PyTorch logic.

```python
import torchvision.models as models

# Basic Chunk: Loading a pre-defined architecture (Case Study application)
def load_resnet_architecture():
    # Load ResNet-152 (The 152-layer network mentioned)
    # weights=None means we just want the architecture, not pre-trained weights
    model = models.resnet152(weights=None)
    return model

# Print architecture to see the "blocks" we will study
resnet152 = load_resnet_architecture()
# print(resnet152) # Would output the full list of layers
