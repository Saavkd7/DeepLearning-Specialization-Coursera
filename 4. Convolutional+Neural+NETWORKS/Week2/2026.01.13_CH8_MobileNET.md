# My Diary

Today  **{{DATE_PRETTY}}**.

## General Counter
It has been    **{{DAY_SINCE_2025_08_18}}** days since I started this diary.

# Repository Counter

Day **{{DAYS_SINCE_REPO_START}}** From I started this repository

# CNN Case Studies: MobileNets

## 1. The Motivation
Traditional CNNs (like VGG) are computationally expensive. Running them on a mobile phone (low battery, low compute) is difficult.
**MobileNets** solve this by replacing standard convolutions with **Depthwise Separable Convolutions**, drastically reducing the number of parameters and computations.


## 2. The Core Mechanism: Depthwise Separable Convolution
This technique splits a standard convolution into two separate, cheaper steps:

### Step 1: Depthwise Convolution
* **Goal:** Filter the inputs spatially (find edges/features), but **do not mix channels**.
* **Operation:** Apply a single $f \times f$ filter to *each* input channel independently.
    * If input has 3 channels, you use 3 filters.
    * Input $6 \times 6 \times 3 \to$ Intermediate $4 \times 4 \times 3$.
* **Cost:** $f \times f \times n_{out} \times n_{out} \times n_C$.


### Step 2: Pointwise Convolution
* **Goal:** Mix the channels together to create new features.
* **Operation:** Apply a **$1 \times 1$ Convolution** (which we learned earlier) to combine the depthwise outputs.
    * Input $4 \times 4 \times 3 \to$ Output $4 \times 4 \times 5$ (if we want 5 features).
* **Cost:** $1 \times 1 \times n_C \times n_{out} \times n_{out} \times n_C'$.


## 3. Cost Comparison (The "Why")
Let's compare the cost (multiplications) for generating a $4 \times 4 \times 5$ output from a $6 \times 6 \times 3$ input using $3 \times 3$ filters.

* **Standard Convolution:**
    * Formula: $f \times f \times n_C \times n_{out}^2 \times n_C'$
    * Calc: $3 \times 3 \times 3 \times 4 \times 4 \times 5 = \mathbf{2,160}$ ops.

* **Depthwise Separable:**
    * Depthwise: $3 \times 3 \times 4 \times 4 \times 3 = 432$ ops.
    * Pointwise: $1 \times 1 \times 3 \times 4 \times 4 \times 5 = 240$ ops.
    * Total: $432 + 240 = \mathbf{672}$ ops.

* **Result:** $672 / 2160 \approx 0.31$. It is **~3x to 10x cheaper** depending on hyperparameters!
    * General Ratio Formula: $\frac{1}{n_C'} + \frac{1}{f^2}$.


## 4. Relation to Earlier Concepts
* **1x1 Convolutions:** The "Pointwise" step is literally the $1 \times 1$ convolution we studied for Inception networks. MobileNets treat it as a fundamental building block to mix information across channels after spatial filtering.
* **Parameter Sharing:** Depthwise convolution takes parameter sharing to the extremeâ€”each filter is shared spatially but restricted to a single channel, minimizing weights.

## 5. Basic Chunk Implementation
In PyTorch, a Depthwise convolution is achieved by setting `groups=in_channels`.

```python
import torch.nn as nn

def depthwise_separable_conv(in_channels, out_channels, stride=1):
    """
    Creates a Depthwise Separable Convolution block.
    """
    return nn.Sequential(
        # Step 1: Depthwise (groups = in_channels)
        nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=stride, padding=1, groups=in_channels, bias=False),
        nn.BatchNorm2d(in_channels),
        nn.ReLU(inplace=True),
        
        # Step 2: Pointwise (1x1 conv)
        nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False),
        nn.BatchNorm2d(out_channels),
        nn.ReLU(inplace=True)
    )
