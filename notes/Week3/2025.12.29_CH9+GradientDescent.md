---
# My Diary

Today  **Monday, 29 Dec 2025**.

## General Counter
It has been    **134** days since I started this diary.

# Repository Counter

Day **6** From I started this repository

# Deep Learning Fundamentals: Gradient Descent Implementation

## 1. Executive Summary
To train a Neural Network, we perform a loop of **Forward Propagation** (Prediction) and **Backpropagation** (Correction).
While Logistic Regression only had to correct one layer of weights, a Neural Network must correct **two** (or more). We calculate the error at the output and propagate it backward, using the Chain Rule to determine exactly how much each parameter ($W^{[1]}, b^{[1]}, W^{[2]}, b^{[2]}$) contributed to the mistake.

## 2. Technical Deep Dive

### The Dimensions
* **$n^{[0]}$ ($n_x$):** Input features.
* **$n^{[1]}$:** Hidden units.
* **$n^{[2]}$:** Output units (1 for binary classification).
* **$m$:** Number of examples.

### Phase 1: Forward Propagation (The Prediction)
*Calculated across all $m$ examples simultaneously.*
1.  $Z^{[1]} = W^{[1]}X + b^{[1]}$
2.  $A^{[1]} = g^{[1]}(Z^{[1]})$  *(e.g., Tanh or ReLU)*
3.  $Z^{[2]} = W^{[2]}A^{[1]} + b^{[2]}$
4.  $A^{[2]} = \sigma(Z^{[2]})$  *(Sigmoid for output)*


### Phase 2: Backpropagation (The Correction)
*We calculate gradients from right (output) to left (input).*

**Layer 2 (Output):**
1.  $dZ^{[2]} = A^{[2]} - Y$
    * *Error at the output.*
2.  $dW^{[2]} = \frac{1}{m} dZ^{[2]} A^{[1]T}$
3.  $db^{[2]} = \frac{1}{m} \text{np.sum}(dZ^{[2]}, \text{axis}=1, \text{keepdims=True})$

**Layer 1 (Hidden):**
4.  $dZ^{[1]} = (W^{[2]T} dZ^{[2]}) * g'^{[1]}(Z^{[1]})$
    * **Crucial:** The `*` represents **element-wise multiplication**.
    * $g'^{[1]}$ is the derivative of the hidden activation (e.g., $1 - (A^{[1]})^2$ for Tanh).
5.  $dW^{[1]} = \frac{1}{m} dZ^{[1]} X^T$
6.  $db^{[1]} = \frac{1}{m} \text{np.sum}(dZ^{[1]}, \text{axis}=1, \text{keepdims=True})$


### Phase 3: The Update
$$W^{[l]} = W^{[l]} - \alpha \cdot dW^{[l]}$$
$$b^{[l]} = b^{[l]} - \alpha \cdot db^{[l]}$$
*Where $\alpha$ is the learning rate.*

## 3. "In Plain English"

### The "Blame Game" Analogy
Imagine a two-stage assembly line making toys.
* **Forward Prop:** Worker 1 (Hidden Layer) builds the body. Worker 2 (Output Layer) paints it.
* **Cost Function:** The Quality Inspector sees the toy is ugly (Error).
* **Backprop (Layer 2):** The Inspector screams at Worker 2: "You painted it wrong!" ($dZ^{[2]}$). Worker 2 calculates how much he needs to adjust his spray gun ($dW^{[2]}$).
* **Backprop (Layer 1):** Worker 2 defends himself: "I painted it bad because Worker 1 built a crooked body!" ($W^{[2]T}dZ^{[2]}$). Now Worker 1 gets yelled at ($dZ^{[1]}$) and figures out how to fix his hammer ($dW^{[1]}$).

## 4. Expert Nuance

### The `keepdims=True` SafetyNet
In the formulas for $db$, we use `np.sum(..., keepdims=True)`.
* **Without it:** Python might output a rank-1 array of shape `(n,)`. This can cause subtle broadcasting bugs where dimensions mismatch later in the code.
* **With it:** Python forces the output to be `(n, 1)`, which is a proper column vector. This guarantees your matrix algebra remains consistent.

### Random Initialization
Unlike Logistic Regression, you **cannot** initialize weights to zero ($W = 0$) in a Neural Network. If you do, every neuron in the hidden layer will learn the exact same feature (Symmetry Problem). You must initialize $W$ randomly (e.g., `np.random.randn() * 0.01`).

## 5. Implementation Code

```python
import numpy as np

def update_parameters(parameters, grads, learning_rate=1.2):
    """
    Updates parameters using gradient descent
    
    Arguments:
    parameters -- python dictionary containing W1, b1, W2, b2
    grads -- python dictionary containing dW1, db1, dW2, db2
    """
    W1 = parameters["W1"]
    b1 = parameters["b1"]
    W2 = parameters["W2"]
    b2 = parameters["b2"]
    
    dW1 = grads["dW1"]
    db1 = grads["db1"]
    dW2 = grads["dW2"]
    db2 = grads["db2"]
    
    # Update rule for each parameter
    W1 = W1 - learning_rate * dW1
    b1 = b1 - learning_rate * db1
    W2 = W2 - learning_rate * dW2
    b2 = b2 - learning_rate * db2
    
    parameters = {"W1": W1, "b1": b1, "W2": W2, "b2": b2}
    
    return parameters
