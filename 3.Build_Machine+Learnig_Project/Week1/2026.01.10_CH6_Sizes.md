# My Diary

Today  **Saturday, 17 Jan 2026**.

## General Counter
It has been    **153** days since I started this diary.

# Repository Counter

Day **25** From I started this repository

# Machine Learning Strategy: Size of Dev and Test Sets

## 1. The Old Rules (Small Data)
In the early days of machine learning (with 100 to 10,000 examples), standard splits were common:
* **70/30 Split:** 70% Training, 30% Test.
* **60/20/20 Split:** 60% Training, 20% Dev, 20% Test.
These rules made sense when data was scarce.


## 2. The Modern Rules (Big Data)
In the era of **Big Data** (e.g., 1,000,000+ examples), these old ratios are wasteful. You don't need 20% of a million examples (200,000) just to tune hyperparameters.

**Recommended Split for Big Data:**
* **98 / 1 / 1 Split:** 98% Training, 1% Dev, 1% Test.
* **Why?**
    * **Training:** Deep learning models are "hungry" for data. You want to give the model as much training data as possible.
    * **Dev/Test:** 1% of a million is **10,000 examples**. This is plenty to evaluate performance with high confidence.


## 3. How big should they be? (Guidelines)

### A. Size of Dev Set
* **Purpose:** To verify which of your algorithms/models is performing better.
* **Guideline:** Set it to be big enough to detect differences between algorithms. You don't need more than that.


### B. Size of Test Set
* **Purpose:** To give you a high-confidence unbiased estimate of the final system's performance.
* **Guideline:** Set it just big enough to give you that confidence. If 10,000 examples give you a statistically significant result, you don't need 100,000.
