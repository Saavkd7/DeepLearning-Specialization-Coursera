# My Diary

Today  **{{DATE_PRETTY}}**.

## General Counter
It has been    **{{DAY_SINCE_2025_08_18}}** days since I started this diary.

# Repository Counter

Day **{{DAYS_SINCE_REPO_START}}** From I started this repository

# Machine Learning Strategy: Moving the Target

## 1. The Core Philosophy: The Target
Think of your **Dev Set + Metric** as a **Target**.
* Your team spends months shooting arrows (training models) to hit the bullseye.
* **The Problem:** Sometimes, midway through a project, you realize the target is in the wrong place. If you hit the bullseye, the users are still unhappy.
* **The Solution:** Move the target. Do not keep optimizing for a metric that doesn't reflect what you actually care about.


## 2. Case Study 1: The "Porn" Problem (Changing the Metric)
Imagine you have two Cat Classifiers:

| Algorithm | Error Rate (Metric) | Behavior |
| :--- | :--- | :--- |
| **A** | **3%** (Winner) | Lets through pornographic images labeled as cats. |
| **B** | 5% (Loser) | Blocks porn, but misses a few more cats. |

* **The Conflict:** Your metric (Accuracy) says **A** is better. But you and your users prefer **B** because showing porn is unacceptable.
* **The Fix:** Your metric is wrong. You need to change the evaluation metric to penalize pornographic errors much more heavily (e.g., give them a weight of 10 or 100).
    * *Old Metric:* Count all errors equally.
    * *New Metric:* Weighted error where porn mistakes cost 10x more.


## 3. Case Study 2: The "High-Quality" Trap (Changing the Dev Set)
* **The Setup:** You train and test on high-quality, professional cat photos downloaded from the web. Algorithm A does great here.
* **The Reality:** When you launch the mobile app, users upload blurry, poorly framed, low-resolution photos. Algorithm A fails, but Algorithm B (which did worse on the pro photos) actually works better on the blurry ones.
* **The Conflict:** Doing well on your Dev Set does not predict doing well in the real application.
* **The Fix:** Change your **Dev and Test Sets**. You must populate them with the blurry, amateur mobile photos that represent the actual data you need to handle.


## 4. Orthogonalization of Metrics
This process highlights a key separation of concerns:
1.  **Place the Target:** Define the metric (e.g., weighted error) that represents "success" for the user.
2.  **Aim at the Target:** Tune the cost function ($J$) and hyperparameters to minimize that metric.
*Don't mix these steps. Define what you want first, then figure out how to get it*.
