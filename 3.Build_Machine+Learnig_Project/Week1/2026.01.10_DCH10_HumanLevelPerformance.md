# My Diary

Today  **Saturday, 17 Jan 2026**.

## General Counter
It has been    **153** days since I started this diary.

# Repository Counter

Day **25** From I started this repository

# Human-Level Performance: Defining the Proxy for Bayes Error

## 1. Defining "Human-Level"
The term "Human-Level" can be vague. To use it effectively for optimization, you must define it based on your goal.

### Example: Medical Image Classification
Suppose we measure the error rates for diagnosing a disease from X-rays:
* (a) Typical human: **3.0%**
* (b) Typical doctor: **1.0%**
* (c) Experienced doctor: **0.7%**
* (d) Team of experienced doctors: **0.5%**

**Which one is "Human-Level"?**
* **For Deployment:** If your goal is just to show the system works, surpassing the "Typical Doctor" (1%) might be enough.
* **For Machine Learning Strategy (Bayes Error):** You should pick the **Team of Doctors (0.5%)**.
    * *Why?* Bayes Error is the theoretical limit (the best possible function). Since a team of humans can achieve 0.5%, we know Bayes Error is $\le 0.5\%$. You want the tightest possible estimate to know how much room you have to improve.


## 2. Using the Definition for Analysis
Your choice of "Human-Level" drastically changes how you prioritize your work (Bias vs. Variance), especially as your model gets better.

### Scenario A: High Bias (Clear Decision)
* **Train Error:** 5%
* **Dev Error:** 6%
* **Human (Best):** 0.5%
* **Analysis:**
    * Avoidable Bias: $5\% - 0.5\% = 4.5\%$
    * Variance: $6\% - 5\% = 1\%$
* **Conclusion:** Focus on **Bias** (bigger network). The precise definition of human error doesn't matter much here because the gap is huge.

### Scenario B: High Variance (Clear Decision)
* **Train Error:** 1%
* **Dev Error:** 5%
* **Human (Best):** 0.5%
* **Analysis:**
    * Avoidable Bias: $1\% - 0.5\% = 0.5\%$
    * Variance: $5\% - 1\% = 4\%$
* **Conclusion:** Focus on **Variance** (regularization). Again, the definition doesn't change the decision.

### Scenario C: The "Approaching Human-Level" Trap
* **Train Error:** 0.7%
* **Dev Error:** 0.8%
* **Analysis:**
    * *If you used "Typical Doctor" (1%) as baseline:* You would think your bias is negative (better than human) and stop trying to fit the training set.
    * *If you use "Team" (0.5%) as baseline:*
        * Avoidable Bias: $0.7\% - 0.5\% = 0.2\%$
        * Variance: $0.8\% - 0.7\% = 0.1\%$
* **Conclusion:** **Avoidable Bias** is actually the bigger problem ($0.2 > 0.1$). You should keep trying to fit the training set. Without the precise definition (0.5%), you would miss this opportunity.


## 3. Summary
* **Human-Level Error** is a proxy for **Bayes Error**.
* **Avoidable Bias** = Training Error - Human-Level Error.
* **Variance** = Dev Error - Training Error.
* **Guideline:** As your model improves and gets close to human performance, having an accurate (lower) estimate of Bayes Error becomes critical to deciding between bias and variance tactics.
