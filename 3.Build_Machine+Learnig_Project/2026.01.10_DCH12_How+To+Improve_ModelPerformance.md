# My Diary

Today  **{{DATE_PRETTY}}**.

## General Counter
It has been    **{{DAY_SINCE_2025_08_18}}** days since I started this diary.

# Repository Counter

Day **{{DAYS_SINCE_REPO_START}}** From I started this repository

# How to Improve Model Performance: A Systematic Approach

## 1. The Two Fundamental Assumptions
To get a supervised learning system to work well, you fundamentally need to satisfy two conditions in order:

1.  **Fit the Training Set:** You must be able to drive the training error down close to Bayes Error (low Avoidable Bias).
2.  **Generalize to the Dev Set:** The model must perform almost as well on data it hasn't seen as it does on the training data (low Variance).



## 2. Diagnosis & Solution Strategy
Depending on where your error gap lies (as discussed in previous videos), you should apply specific sets of tactics.

### A. Reducing Avoidable Bias (Training Set Problem)
* **Diagnosis:** There is a large gap between **Human-Level Performance** (Bayes Error) and **Training Error**.
* **Solutions:**
    * **Train a Bigger Model:** More layers or more hidden units. This is the most reliable way to reduce bias.
    * **Train Longer:** Run more epochs or use a better optimizer (e.g., Adam, RMSprop).
    * **Change Architecture:** Try new model types (RNNs, CNNs) or activation functions that might suit the problem better.

### B. Reducing Variance (Dev Set Problem)
* **Diagnosis:** There is a large gap between **Training Error** and **Dev Error**.
* **Solutions:**
    * **Get More Data:** The gold standard for fixing variance.
    * **Regularization:** Apply L2 Regularization, Dropout, or Data Augmentation.
    * **Change Architecture:** Finding a better-suited architecture can sometimes help variance as well.



## 3. Summary Table

| Problem | Indicator | Actionable Tactics |
| :--- | :--- | :--- |
| **High Avoidable Bias** | Training Error $\gg$ Human Error | • Bigger Network<br>• Train Longer (Adam/Momentum)<br>• New Architecture |
| **High Variance** | Dev Error $\gg$ Training Error | • More Data<br>• Regularization (L2, Dropout)<br>• Data Augmentation |

Mastering this workflow makes you more strategic and efficient than many ML teams who blindly try "more data" or "different models" without diagnosing the root cause first.
