

# My Diary

Today  **{{DATE_PRETTY}}**.

## General Counter
It has been    **{{DAY_SINCE_2025_08_18}}** days since I started this diary.

# Repository Counter

Day **{{DAYS_SINCE_REPO_START}}** From I started this repository

# Training and Testing on Different Distributions

## 1. The Scenario: The "Data Hunger" Dilemma
Deep learning models need massive amounts of data. Often, you have:
1.  **Small "Target" Data:** The data you actually care about (e.g., blurry mobile phone photos uploaded by users). This is scarce (e.g., 10,000 images).
2.  **Large "Cheap" Data:** Data that is easy to get but slightly different (e.g., high-res professional cat photos from the web). This is abundant (e.g., 200,000 images).

**The Goal:** You want the model to perform well on the **Target** (Mobile) data.


## 2. Option 1: Random Shuffle (Bad Strategy)
You mix all data together (210,000 total) and randomly split it into Train/Dev/Test.
* **The Result:** Your Dev/Test sets will be 95% "Web" images and only 5% "Mobile" images.
* **The Problem:** You are optimizing your team to hit a target (Web images) that you don't actually care about. You might get 99% accuracy on the Dev set, but it will fail on the actual mobile app because you barely tested on it.

## 3. Option 2: Strategic Split (Recommended Strategy)
You keep the distributions separate to ensure you are aiming at the right target.

* **Training Set:** Includes **all** the "Web" data (200k) + **some** "Mobile" data (5k).
    * *Total:* 205,000 images.
    * *Purpose:* Teach the model generally what a cat looks like.
* **Dev/Test Sets:** Include **ONLY** "Mobile" data (2.5k each).
    * *Purpose:* Verify the model works on the specific data you care about.

**Trade-off:** Your Training distribution is now different from your Dev/Test distribution. However, this is better because your **Target (Dev Set)** correctly reflects the real-world application.


## 4. Another Example: Speech Recognition
* **Product:** A voice-activated rearview mirror (noisy car environment).
* **Data Sources:**
    1.  **General Speech Data (500k):** Audiobooks, smart speakers, voice keyboards (Clean/Different).
    2.  **Rearview Mirror Data (20k):** Actual recordings from the car (Noisy/Target).
* **Strategy:**
    * **Train:** 500k General + 10k Rearview.
    * **Dev/Test:** 5k Rearview + 5k Rearview.
    * *Result:* The model learns from a massive dataset but is optimized and evaluated specifically for the car environment.
