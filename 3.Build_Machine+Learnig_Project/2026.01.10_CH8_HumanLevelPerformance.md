# My Diary

Today  **{{DATE_PRETTY}}**.

## General Counter
It has been    **{{DAY_SINCE_2025_08_18}}** days since I started this diary.

# Repository Counter

Day **{{DAYS_SINCE_REPO_START}}** From I started this repository



# Machine Learning Strategy: Comparing to Human-Level Performance

## 1. Why Compare to Humans?
In recent years, it has become standard practice to benchmark ML systems against human performance. There are two main reasons for this:
1.  **Feasibility:** Deep learning algorithms are now powerful enough to actually compete with or surpass humans on many tasks.
2.  **Efficiency:** The workflow for building an ML system is much smoother when you are trying to mimic something humans can do. You can rely on human intuition to guide the process.

## 2. The Performance Trajectory
There is a typical pattern when working on perception tasks (like vision or speech):
* **Rapid Progress:** Accuracy improves quickly as the model approaches human-level performance.
* **The Plateau:** Once the model surpasses humans, progress often slows down significantly.
* **The Limit:** It eventually asymptotes towards a theoretical ceiling called the **Bayes Optimal Error**.


## 3. What is Bayes Optimal Error?
**Bayes Optimal Error** is the absolute best possible error rate that can theoretically be achieved.
* It is rarely 0%.
* **Example:** In speech recognition, some audio clips are so noisy that it is physically impossible to distinguish the words. In cat recognition, some images are too blurry to tell.
* No system (human or machine) can ever surpass Bayes Optimal Error.

## 4. Why Progress Slows After Beating Humans
When your model is **worse** than humans, you have powerful tools to improve it:
1.  **Get Labeled Data:** You can hire humans to label more data (since they are still the "ground truth").
2.  **Error Analysis:** You can look at mistakes and ask, "Why did the human get this right?" to gain insight.
3.  **Bias/Variance Analysis:** You can use human error as a proxy for Bayes error to determine if you have a bias or variance problem.

**The Problem:** Once your model is **better** than humans, these tools stop working efficiently. You can't ask a human to correct a model that is smarter than they are.
